{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25868df",
   "metadata": {},
   "source": [
    "<center><b><h1>Fundamentos da Inteligência Artificial</h1></b><center>\n",
    "<hr>\n",
    "\n",
    "Neste notebook irei armazenar todos os conhecimentos obtidos durante os meus estudos de 2025 sobre tudo que engloba a inteligência artifícial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b348fd",
   "metadata": {},
   "source": [
    "## História da IA\n",
    "\n",
    "Tudo começou com a obra seminal \"Computing Machinery and Intelligence\" em 1950 ministrada pelo Alan Turing que foi o responsável por criar uma pergunta sobre se as máquinas seriam capazes de pensar, contudo foi só após a segunda geurra mundial que então o nome da inteligência artificial começou a se popularizar graças ao John McCarthy também criador da linguagem LISP em 1958.\n",
    "Por fim, em 1967 Frank Rosenblatt constrói o Perceptron I, sendo este o primeiro computador com base em rede neural, tendo um livro publicado 1 ano depois chamado Perceptron.\n",
    "\n",
    "A inteligência artificial é um tópico que foi congelado diversas vezes pelo fato de não obterem avanços científicos, perdendo investimentos e impedindo avanço. O primeiro inverno ocorreu entre 1974 e 1980 após a rede perceptron ter suas limitações expostas. E só foi quando o backpropagation surgiu para lidar com estas limitações, que os investimentos voltaram.\n",
    "\n",
    "O segundo inverno da inteligência artificial foi quando os avanços foram tantos que infelizmente os hardwares eram incapazes de rodar os algoritmos, então foi no início dos anos 2000 que conseguimos retornar ao investimento com as pesquisas de inteligência artificial. E para o momento a pergunta que ficou foi, será que teremos um outro inverno devido as limitações encontradas durante o seu desenvolvimento?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53680bab",
   "metadata": {},
   "source": [
    "## Aplicações da Inteligência Artificial\n",
    "\n",
    "A IA está presente no nosso cotidiano de forma cada vez mais frequente, encontramos estas nos Chatbots, na área da saúde, jurídica, vendas, imóveis e quaisquer outras áreas que venham desejar a implementação de softwares sofisticados e capazes de gerir funcionalidades que vão de simples a complexas. Já que a IA é capaz inclusive de identificar fraudes nos dias atuais, existindo obviamente uma taxa de falha como todo algoritmo, porém alcançando boons resultados.\n",
    "\n",
    "E bom, podemos utilizar a Inteligência artíficial até mesmo para reconhecimento facial e vocal, assim como identificação de objetos em um ambiente fechado ou aberto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ee52c",
   "metadata": {},
   "source": [
    "## Desafios Atuais da IA\n",
    "\n",
    "* Viés Algorítmico\n",
    "* Privacidade e dados\n",
    "* Direitos autorais\n",
    "* Substituição de empregos\n",
    "* Deepfakes e segurança\n",
    "* Leis e regulamentações\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d6634",
   "metadata": {},
   "source": [
    "## IA Simbólica & IA Conexionista\n",
    "\n",
    "As inteligências artificiais simbólicas foram as primeiras a surgirem quando falamos do desenvolvimento e da história como um todo do tema, dominando as pesquisas entre as décadas de 1950 e 1980. Ela é definida a partir da criação de **regras explícitas** que se baseiam majoritariamente na **matemática e na lógica formal**, utilizando representações como lógica de predicados, árvores de decisão e sistemas de regras if-then. \n",
    "\n",
    "O conhecimento neste paradigma é codificado manualmente por engenheiros de conhecimento, que extraem expertise de especialistas humanos e a transformam em regras processáveis. O processamento ocorre através de **mecanismos de inferência lógica**, como encadeamento para frente (forward chaining) ou para trás (backward chaining), permitindo que o sistema derive conclusões a partir das regras estabelecidas.\n",
    "\n",
    "Geralmente este tipo de inteligência possui passos bem direcionados e **interpretáveis** - é possível rastrear exatamente qual regra foi aplicada em cada decisão. Contudo, são sistemas limitados pelo **custo elevado da engenharia de conhecimento** (o chamado Knowledge Engineering Bottleneck) e pela **rigidez às variações não previstas nas regras**, falhando catastroficamente quando confrontados com situações fora do domínio especificado. \n",
    "\n",
    "Um exemplo clássico de aplicação destas IAs simbólicas é o **MYCIN**, sistema especialista desenvolvido em Stanford que auxilia em diagnóstico de infecções bacterianas e recomendação de antibióticos, operando com aproximadamente 600 regras de produção e alcançando performance comparável a especialistas humanos em seu domínio específico.\n",
    "\n",
    "---\n",
    "\n",
    "Agora quando falamos da **IA Conexionista**, estamos adentrando em uma abordagem fundamentalmente diferente. A ideia por trás deste tipo de IA vem do **aprendizado a partir de padrões e relacionamentos extraídos dos dados**, não de regras programadas explicitamente. O conhecimento aqui é **implícito e distribuído** nos pesos das conexões de uma rede neural artificial, inspirada no processamento paralelo distribuído observado em sistemas biológicos.\n",
    "\n",
    "Diferente do paradigma simbólico onde o fluxo é Conhecimento → Regras → Inferência, no conexionismo temos: Dados → Treinamento → Generalização. O sistema aprende através de **ajuste iterativo de parâmetros** (pesos sinápticos) utilizando algoritmos como backpropagation e técnicas de otimização, permitindo que o conhecimento **emerja** do processo de treinamento ao invés de ser explicitamente programado.\n",
    "\n",
    "Estes sistemas requerem **grande volume de dados** para treinamento adequado e apresentam um trade-off fundamental: alta performance em tarefas complexas versus baixa interpretabilidade (problema da caixa-preta). Exemplos práticos de sua funcionalidade no mundo real estão presentes no reconhecimento de imagens através de CNNs (Convolutional Neural Networks), processamento de linguagem natural com Transformers, e demais arquiteturas de **Deep Learning** - que representa a evolução moderna do paradigma conexionista com redes de múltiplas camadas capazes de aprender representações hierárquicas complexas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84d875",
   "metadata": {},
   "source": [
    "## Características de problemas que podem ser resolvidos por IA.[]\n",
    "\n",
    "* Natureza Heurística: Problemas onde o número de soluções cresce exponencialmente, tornando busca exaustiva inviável. Métodos heurísticos exploram seletivamente o espaço, aceitando soluções de alta qualidade sem garantia de otimalidade global.\n",
    "* Aprendizado contínuo: Problemas onde padrões mudam ao longo do tempo, exigindo atualização contínua do modelo sem esquecer conhecimento anterior.\n",
    "Exemplo: Detecção de fraude adaptando-se a novas técnicas, ou sistemas de recomendação ajustando-se a tendências sazonais.\n",
    "* Grandes volumes de dados: Problemas com relações complexas impossíveis de codificar manualmente. Modelos aprendem padrões automaticamente de dados. Grande volume evita overfitting (memorização) e underfitting (simplicidade excessiva).\n",
    "Exemplo: Identificação de tumores via aprendizado supervisionado - CNNs treinadas com milhares de exames rotulados aprendem características discriminativas automaticamente.\n",
    "\n",
    "\n",
    "Após isto é necessário entender como prosseguir, identificando:\n",
    "\n",
    "* A natureza dos dados, se são estruturados, não estruturados ou sequenciais.\n",
    "* O tipo de aprendizagem, se supervisionada, não-supervisionada ou por reforço.\n",
    "* E identificar qual a melhor saída, se classificação, regressão, geração ou otimização como exemplo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f47628",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizado — Aprendizado Supervisionado\n",
    "Modelos de aprendizado supervisionado são modelos dos quais temos informações tanto sobre os parâmetros de saída quanto entrada (dados rotulados), este modelo pode ser utilizado para identificar por exemplo rostos humanos dentro de um conjunto de imagens que possuem respostas corretas para cada rosto em seu banco de dados, se humano ou não-humano. Após treinarmos o nosso modelo de aprendizado de máquina, ele obtém um padrão estabelecido que pode ser utilizado em outros bancos de imagens de mesmo tipo para identificação destes padrões.\n",
    "\n",
    "Agora falando sobre os tipos de categorias existentes dentro do modelo de aprendizado supervisionado, podemos subdividi-lo em dois tipos, os modelos supervisionados de **Regressão e Classificação.**\n",
    "*   **Regressão:** Utilizamos a regressão quando queremos explorar o relacionamento entre duas ou mais variáveis, a ideia é a obtenção de informações sobre uma delas a partir dos valores conhecidos das outras que estão correlacionadas. A regressão é uma técnica para modelar o relacionamento entre variáveis quando se tem uma saída contínua, permitindo fazer predições. A regressão pode ser tanto **determinística quanto não-determinística, quanto simples ou múltipla.**\n",
    "    * **Determinística:** Quando há forte relação entre duas ou mais variáveis, como por exemplo prever o consumo de combustível (litros por 100km rodados) em função de sua velocidade.\n",
    "    * **Não determinística:** Quando existe uma randomicidade considerável na relação entre duas ou mais variáveis, como por exemplo a altura estimada dos filhos em base da altura dos pais.\n",
    "    * **Simples:** Na regressão linear simples, a representação entre uma variável dependente Y e uma variável independente X é modelada através da seguinte equação matemática: <math><mi>y</mi><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi><mo>+</mo><mi>ε</mi></math> onde ε (épsilon) representa o erro ou resíduo - a diferença entre o valor real e o valor predito pelo modelo, sendo a variável dependente o resultado e a independente o preditor, temos o coeficiente linear conhecido também como intercepto que é o valor de Y quando nossa variável independente é igual a 0, enquanto o coeficiente angular (β₁) é multiplicado pelo valor de X, determinando a variação de Y por unidade de X.\n",
    "    \n",
    "    * **Múltipla:**  A regressão linear múltipla estende a fórmula para incluir múltiplas variáveis independentes (X₁, X₂, ..., Xₙ), cada uma com seu próprio coeficiente angular (β₁, β₂, ..., βₙ). O intercepto (β₀) é o valor de Y quando todas as variáveis independentes são iguais a 0.\n",
    "\n",
    "<hr>\n",
    "\n",
    "*   **Classificação:** O objetivo dos modelos de classificação está na categorização dos dados em **classes discretas** pré-definidas. Diferentemente da regressão que prediz valores contínuos, a classificação atribui observações a categorias específicas, gerando **saídas categóricas**. A classificação pode ser:\n",
    "    * **Binária:** Duas classes possíveis.\n",
    "        * **Exemplo:** Classificar e-mail como spam ou não-spam; diagnosticar presença ou ausência de doença.\n",
    "    * **Multiclasse:** Três ou mais classes mutuamente exclusivas.\n",
    "        * **Exemplo:** Classificar espécie de flor (setosa/versicolor/virginica); prever se o clima é bom, regular ou ruim para jogar golf; reconhecer dígitos manuscritos (0-9).\n",
    "    * **Multilabel:** Múltiplas categorias não-exclusivas (uma observação pode pertencer a várias classes simultaneamente).\n",
    "        * **Exemplo:** Atribuir tags a artigos (pode ser \"esportes\" E \"negócios\" ao mesmo tempo).\n",
    "\n",
    "**<center> Dentre os algoritmos mais utilizados para classificação, destacam-se:</center>**\n",
    "\n",
    "* **Regressão Logística:** Mais utilizada para obtenção de resultados binários, este modelo nos permite estimar a probabilidade associada a ocorrência de determinado evento de forma clara. Este tipo de modelo visa estimar a probabilidade de uma variável dependente assumir determinado valor em função de outras variáveis independentes. O modelo utiliza a função logística (sigmoide) para transformar a combinação linear das variáveis em log-odds (logaritmo da razão das chances), que é então convertido em probabilidade entre 0 e 1. Dentre suas dificuldades temos:\n",
    "    * Requer codificação de variáveis categóricas (como one-hot encoding), o que pode gerar alta dimensionalidade e afetar performance quando há muitas categorias\n",
    "    * Vulnerável a overfitting quando há muitas variáveis em relação ao número de observações (pode ser mitigado com regularização L1/L2)\n",
    "    * Limitação para padrões não-lineares: assume relacionamento linear entre variáveis independentes e log-odds, requerendo engenharia de features (termos polinomiais, interações) para capturar relações complexas\n",
    "        \n",
    "* **Árvores de decisão:** Temos modelos tanto de regressão quanto de classificação para as árvores de decisão, contudo aqui explicaremos o de classificação. Bom, é importante entender que toda árvore possuí uma estrutura, e dentro do nosso contexto de aprendizado chamamos de nó raiz (início da árvore), nós de decisão (ou nós internos, onde são aplicados testes sobre características específicas, determinando qual ramo seguir), e os nós folhas (contêm a classe predita, ex: 'Yes/No' para binária, ou 'Espécie A/B/C' para multiclasse). Durante o treinamento, a árvore é construída dividindo recursivamente os dados com base em características que melhor separam as classes, utilizando métricas como Índice de Gini ou Entropia. Para classificar novos dados, percorre-se a árvore desde a raiz, aplicando os testes em cada nó de decisão até chegar a um nó folha que contém a classe predita, dentre suas dificuldades temos:\n",
    "    * Alta tendência a overfitting (especialmente árvores profundas)\n",
    "    * Instabilidade - pequenas mudanças nos dados podem alterar a estrutura\n",
    "    * Pode criar árvores excessivamente complexas sem poda\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfe18a",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "* **:**\n",
    "\n",
    "* **:**\n",
    "\n",
    "\n",
    "* **:**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
